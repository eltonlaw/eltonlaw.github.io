<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/3cbcbbfcdeb7e3db.css" crossorigin="" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/bd17e4652862e3d3.css" crossorigin="" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-90045f0723cd8e5e.js" crossorigin=""/><script src="/_next/static/chunks/fd9d1056-d03af0e963d7a2f3.js" async="" crossorigin=""></script><script src="/_next/static/chunks/69-02072d3a2eb6f573.js" async="" crossorigin=""></script><script src="/_next/static/chunks/main-app-b262cd48234fe111.js" async="" crossorigin=""></script><script src="/_next/static/chunks/250-92aea3426083640b.js" async=""></script><script src="/_next/static/chunks/app/wiki/page-674321a20e7d3b84.js" async=""></script><title>eltonlaw</title><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" crossorigin="" noModule=""></script></head><body><div class="RootLayout_container__tH3RP"><div class="RootLayout_masthead__LsRd7"><h3><a class="RootLayout_titleLink__VQPJ9" href="/">eltonlaw</a><small> sundries</small></h3><a class="RootLayout_titleLink__VQPJ9" href="https://github.com/eltonlaw"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"></path></svg></a></div><div class="postFrontmatter"><h2 class="PostFrontmatter_postTitle__fY2bg">Large Language Models</h2><span class="PostFrontmatter_postDate__ncWjv">Last Updated: 2023-12-19 5:59PM</span></div>
<h3>Inference Pipeline</h3>
<ol>
<li>Raw strings are mapped to tokens in a vocabulary where a vocab looks like <code>{&quot; &quot;: 0,  &quot;lo&quot;: 1, &quot;hel&quot;: 2, &quot;r&quot;: 3, &quot;wo&quot;: 4, &quot;ld&quot;: 5}</code> and the resulting tokens for <code>&quot;hello world&quot;</code> would be <code>[2, 1, 0, 4, 3, 5]</code>. Part of GPT-2&#x27;s vocab is below. It uses Byte-Pair Encoding so tokens are parts of words. There are a lot of <code>Ġ</code> characters and those are special, indicating the start of a new word. <code>Ġaut</code> creates a token for the first 3 letters of&quot;author&quot; whereas <code>aut</code> wouldn&#x27;t, instead <code>aut</code>&#x27;s value would substituted in the middle for a word like &quot;nautilus&quot;. There&#x27;s usually a padding and truncation element so that inputs are normalized to be a certain shape.</li>
</ol>
<pre><code>In [1]: from transformers import AutoTokenizer
In [2]: tokenizer = AutoTokenizer.from_pretrained(&quot;gpt2&quot;)
In [3]: tokenizer.get_vocab()
Out[3]:
{&#x27;Ġaut&#x27;: 1960,
 &#x27;roleum&#x27;: 21945,
 &#x27;151&#x27;: 24309,
 &#x27;ascal&#x27;: 27747,
 &#x27;azeera&#x27;: 28535,
 &#x27;Ġchore&#x27;: 30569,
 &#x27;][&#x27;: 7131,
 &#x27;ĠEns&#x27;: 48221,
 ...}
In [4]: len(tokenizer.get_vocab())
Out[4]: 50279
In [5]: tokenizer.encode(&quot;hello world&quot;, return_tensors=&quot;pt&quot;)
Out[5]: tensor([[31373,   995]])
In [6]: tokenizer.encode(&quot;hello world hello world&quot;, return_tensors=&quot;pt&quot;)
Out[6]: tensor([[31373,   995, 23748, 995]])
In [7]: tokenizer.encode(&quot;hello world&quot;, return_tensors=&quot;pt&quot;, max_length=10, padding=&quot;max_length&quot;, truncation=True)
Out[7]: tensor([[31373,   995, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])
In [8]: tokenizer.encode(&quot;hello world&quot;, return_tensors=&quot;pt&quot;, max_length=10, padding=&quot;max_length&quot;, truncation=True)
Out[8]: tensor([[31373]])
</code></pre>
<ol start="2">
<li>Tokens are converted into a numerical representation known as an embedding. Each token would turn into something like <code>[0.14321, 0.098342, -1.12378 ...]</code>). GPT-2 has a vocab size of 50257, and embeddings have size of 768 so the embedding layer is <code>(n_vocab, n_embeddings)</code>. (<code>wte</code> stands for word token embeddings)</li>
</ol>
<pre><code>In [1]: from transformers import AutoModel

In [2]: model = AutoModel.from_pretrained(&quot;gpt2&quot;)

In [3]: model.wte
Out[3]: Embedding(50257, 768)
</code></pre>
<ol start="3">
<li>Feedforward through some fully connected layers and self attention layers</li>
<li>Head layer is of shape <code>(n_embedding, n_vocab)</code></li>
</ol>
<pre><code>In [2]: model = AutoModelForCausalLM.from_pretrained(&quot;gpt2&quot;)

In [3]: model.lm_head
Out[3]: Linear(in_features=768, out_features=50257, bias=False)
</code></pre>
<ol start="5">
<li>Softmax of output values, use token associated with max value as the next token</li>
</ol>
<h3>Finetuning</h3>
<p>Finetuning is when you start with an already trained model as opposed to a randomly initialized model. The benefits to this are that you&#x27;re able to leverage larger general datasets, leverage models trained already and use less resources. Available approaches:</p>
<ol>
<li>Keep pretrained model frozen, remove logits layer, train a classifier on the embedding</li>
<li>Keep pretrained model frozen, attach extra hidden layers to the end</li>
<li>Only freeze parts of the pretrained model, rest is trained, lots of variety in how the selection happens</li>
<li>Don&#x27;t freeze the model, use pretrained model as the initialization values. More prone to catastrophic forgetting.</li>
</ol>
<h3>Uncategorized Notes</h3>
<ul>
<li>Usually the more layers you update the better the performance <sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup></li>
<li>Task-specific datasets and finetuning required. This is difficult because lots of tasks are going to be very difficult to collect datasets for.</li>
<li>The more complicated the task and the less data there is, the more likely the model will fall-back on things it learned during pretraining. Humans don&#x27;t require large supervised datasets to learn most language tasks, at most a tiny number of demonstrations is often enough.</li>
<li>Unsupervised pre-training teaches the model a broad amount of skills and at inference time we can use some combination of those to do the task we give it.</li>
<li>By giving models a task description we can have higher accuracy than without the task description up to a certain point where enough examples of the task have been given.</li>
<li>Meta-learning/Zero-shot transfer is for the idea of providing task specific inputs + instruction only at inference time. There is zero-shot, one-shot, few-shot for how many demonstrations are provided at runtime. Zero and one-shot are relevant distinctions because they&#x27;re closer to human learning. These *-shot learnings are not competing alternatives but have different problem settings.</li>
<li>Curated datasets (using similarity to hand-picked elements) perform better than unfiltered or lightly filtered verions of the same dataset.</li>
<li>T5 beam search using a beam width of 4 and a length penalty of alpha = 0.6</li>
<li>&quot;Larger models can typically use a larger batch size but require a smaller learning rate&quot;</li>
</ul>
<section data-footnotes="true" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p>&quot;Finetuning Open-Source LLMs.&quot; Youtube, uploaded by Sebastian Raschka, 14 Oct. 2023, <a href="https://youtu.be/gs-IDg-FoIQ?si=OCUI22mSHWSfmFK6&amp;t=375">https://youtu.be/gs-IDg-FoIQ?si=OCUI22mSHWSfmFK6&amp;t=375</a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section></div><script src="/_next/static/chunks/webpack-90045f0723cd8e5e.js" crossorigin="" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/3cbcbbfcdeb7e3db.css\",\"style\",{\"crossOrigin\":\"\"}]\n0:\"$L2\"\n"])</script><script>self.__next_f.push([1,"3:HL[\"/_next/static/css/bd17e4652862e3d3.css\",\"style\",{\"crossOrigin\":\"\"}]\n"])</script><script>self.__next_f.push([1,"4:I[7690,[],\"\"]\n6:I[5613,[],\"\"]\n7:I[1778,[],\"\"]\n8:I[5250,[\"250\",\"static/chunks/250-92aea3426083640b.js\",\"124\",\"static/chunks/app/wiki/page-674321a20e7d3b84.js\"],\"\"]\na:I[8955,[],\"\"]\nb:[]\n"])</script><script>self.__next_f.push([1,"2:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/3cbcbbfcdeb7e3db.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"Q6LCT3KCzOxshznwalZC_\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/wiki/large_language_models\",\"initialTree\":[\"\",{\"children\":[\"wiki\",{\"children\":[\"large_language_models\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"wiki\",{\"children\":[\"large_language_models\",{\"children\":[\"__PAGE__\",{},[\"$L5\",[[\"$\",\"div\",null,{\"className\":\"postFrontmatter\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"PostFrontmatter_postTitle__fY2bg\",\"children\":\"Large Language Models\"}],[\"$\",\"span\",null,{\"className\":\"PostFrontmatter_postDate__ncWjv\",\"children\":\"Last Updated: 2023-12-19 5:59PM\"}]]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Inference Pipeline\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Raw strings are mapped to tokens in a vocabulary where a vocab looks like \",[\"$\",\"code\",null,{\"children\":\"{\\\" \\\": 0,  \\\"lo\\\": 1, \\\"hel\\\": 2, \\\"r\\\": 3, \\\"wo\\\": 4, \\\"ld\\\": 5}\"}],\" and the resulting tokens for \",[\"$\",\"code\",null,{\"children\":\"\\\"hello world\\\"\"}],\" would be \",[\"$\",\"code\",null,{\"children\":\"[2, 1, 0, 4, 3, 5]\"}],\". Part of GPT-2's vocab is below. It uses Byte-Pair Encoding so tokens are parts of words. There are a lot of \",[\"$\",\"code\",null,{\"children\":\"Ġ\"}],\" characters and those are special, indicating the start of a new word. \",[\"$\",\"code\",null,{\"children\":\"Ġaut\"}],\" creates a token for the first 3 letters of\\\"author\\\" whereas \",[\"$\",\"code\",null,{\"children\":\"aut\"}],\" wouldn't, instead \",[\"$\",\"code\",null,{\"children\":\"aut\"}],\"'s value would substituted in the middle for a word like \\\"nautilus\\\". There's usually a padding and truncation element so that inputs are normalized to be a certain shape.\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"In [1]: from transformers import AutoTokenizer\\nIn [2]: tokenizer = AutoTokenizer.from_pretrained(\\\"gpt2\\\")\\nIn [3]: tokenizer.get_vocab()\\nOut[3]:\\n{'Ġaut': 1960,\\n 'roleum': 21945,\\n '151': 24309,\\n 'ascal': 27747,\\n 'azeera': 28535,\\n 'Ġchore': 30569,\\n '][': 7131,\\n 'ĠEns': 48221,\\n ...}\\nIn [4]: len(tokenizer.get_vocab())\\nOut[4]: 50279\\nIn [5]: tokenizer.encode(\\\"hello world\\\", return_tensors=\\\"pt\\\")\\nOut[5]: tensor([[31373,   995]])\\nIn [6]: tokenizer.encode(\\\"hello world hello world\\\", return_tensors=\\\"pt\\\")\\nOut[6]: tensor([[31373,   995, 23748, 995]])\\nIn [7]: tokenizer.encode(\\\"hello world\\\", return_tensors=\\\"pt\\\", max_length=10, padding=\\\"max_length\\\", truncation=True)\\nOut[7]: tensor([[31373,   995, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])\\nIn [8]: tokenizer.encode(\\\"hello world\\\", return_tensors=\\\"pt\\\", max_length=10, padding=\\\"max_length\\\", truncation=True)\\nOut[8]: tensor([[31373]])\\n\"}]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"2\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Tokens are converted into a numerical representation known as an embedding. Each token would turn into something like \",[\"$\",\"code\",null,{\"children\":\"[0.14321, 0.098342, -1.12378 ...]\"}],\"). GPT-2 has a vocab size of 50257, and embeddings have size of 768 so the embedding layer is \",[\"$\",\"code\",null,{\"children\":\"(n_vocab, n_embeddings)\"}],\". (\",[\"$\",\"code\",null,{\"children\":\"wte\"}],\" stands for word token embeddings)\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"In [1]: from transformers import AutoModel\\n\\nIn [2]: model = AutoModel.from_pretrained(\\\"gpt2\\\")\\n\\nIn [3]: model.wte\\nOut[3]: Embedding(50257, 768)\\n\"}]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"3\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Feedforward through some fully connected layers and self attention layers\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Head layer is of shape \",[\"$\",\"code\",null,{\"children\":\"(n_embedding, n_vocab)\"}]]}],\"\\n\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"In [2]: model = AutoModelForCausalLM.from_pretrained(\\\"gpt2\\\")\\n\\nIn [3]: model.lm_head\\nOut[3]: Linear(in_features=768, out_features=50257, bias=False)\\n\"}]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"5\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Softmax of output values, use token associated with max value as the next token\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Finetuning\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Finetuning is when you start with an already trained model as opposed to a randomly initialized model. The benefits to this are that you're able to leverage larger general datasets, leverage models trained already and use less resources. Available approaches:\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Keep pretrained model frozen, remove logits layer, train a classifier on the embedding\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Keep pretrained model frozen, attach extra hidden layers to the end\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Only freeze parts of the pretrained model, rest is trained, lots of variety in how the selection happens\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Don't freeze the model, use pretrained model as the initialization values. More prone to catastrophic forgetting.\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"Uncategorized Notes\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Usually the more layers you update the better the performance \",[\"$\",\"sup\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"#user-content-fn-1\",\"id\":\"user-content-fnref-1\",\"data-footnote-ref\":true,\"aria-describedby\":\"footnote-label\",\"children\":\"1\"}]}]]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Task-specific datasets and finetuning required. This is difficult because lots of tasks are going to be very difficult to collect datasets for.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"The more complicated the task and the less data there is, the more likely the model will fall-back on things it learned during pretraining. Humans don't require large supervised datasets to learn most language tasks, at most a tiny number of demonstrations is often enough.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Unsupervised pre-training teaches the model a broad amount of skills and at inference time we can use some combination of those to do the task we give it.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"By giving models a task description we can have higher accuracy than without the task description up to a certain point where enough examples of the task have been given.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Meta-learning/Zero-shot transfer is for the idea of providing task specific inputs + instruction only at inference time. There is zero-shot, one-shot, few-shot for how many demonstrations are provided at runtime. Zero and one-shot are relevant distinctions because they're closer to human learning. These *-shot learnings are not competing alternatives but have different problem settings.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Curated datasets (using similarity to hand-picked elements) perform better than unfiltered or lightly filtered verions of the same dataset.\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"T5 beam search using a beam width of 4 and a length penalty of alpha = 0.6\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"\\\"Larger models can typically use a larger batch size but require a smaller learning rate\\\"\"}],\"\\n\"]}],\"\\n\",[\"$\",\"section\",null,{\"data-footnotes\":true,\"className\":\"footnotes\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"sr-only\",\"id\":\"footnote-label\",\"children\":\"Footnotes\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"id\":\"user-content-fn-1\",\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[\"\\\"Finetuning Open-Source LLMs.\\\" Youtube, uploaded by Sebastian Raschka, 14 Oct. 2023, \",[\"$\",\"a\",null,{\"href\":\"https://youtu.be/gs-IDg-FoIQ?si=OCUI22mSHWSfmFK6\u0026t=375\",\"children\":\"https://youtu.be/gs-IDg-FoIQ?si=OCUI22mSHWSfmFK6\u0026t=375\"}],\" \",[\"$\",\"a\",null,{\"href\":\"#user-content-fnref-1\",\"data-footnote-backref\":\"\",\"aria-label\":\"Back to reference 1\",\"className\":\"data-footnote-backref\",\"children\":\"↩\"}]]}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}]],null]]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"wiki\",\"children\",\"large_language_models\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/bd17e4652862e3d3.css\",\"precedence\":\"next\",\"crossOrigin\":\"\"}]]}]]},[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"wiki\",\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}]]},[null,[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"RootLayout_container__tH3RP\",\"children\":[[\"$\",\"div\",null,{\"className\":\"RootLayout_masthead__LsRd7\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"$undefined\",\"children\":[[\"$\",\"$L8\",null,{\"className\":\"RootLayout_titleLink__VQPJ9\",\"href\":\"/\",\"children\":\"eltonlaw\"}],[\"$\",\"small\",null,{\"children\":\" sundries\"}]]}],[\"$\",\"$L8\",null,{\"className\":\"RootLayout_titleLink__VQPJ9\",\"href\":\"https://github.com/eltonlaw\",\"children\":[\"$\",\"svg\",null,{\"viewBox\":\"0 0 16 16\",\"width\":\"16px\",\"height\":\"16px\",\"children\":[\"$\",\"path\",null,{\"fill\":\"#828282\",\"d\":\"M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z\"}]}]}]]}],[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"loadingScripts\":\"$undefined\",\"hasLoading\":false,\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]]}]}]}],null]],\"initialHead\":[false,\"$L9\"],\"globalErrorComponent\":\"$a\",\"missingSlots\":\"$Wb\"}]]\n"])</script><script>self.__next_f.push([1,"9:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"eltonlaw\"}]]\n5:null\n"])</script><script>self.__next_f.push([1,""])</script></body></html>